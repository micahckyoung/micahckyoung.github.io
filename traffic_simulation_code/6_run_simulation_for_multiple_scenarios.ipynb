{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the purpose of this code is to run the simulation for multiple scenarios and calculate the time differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this file was originally called 250414_scenario_planning_v2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import glob\n",
    "code_path = os.path.join(os.path.dirname(os.getcwd()), 'code')\n",
    "sys.path.append(code_path)\n",
    "from simulation_v7 import *\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initial settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "processed_dir = os.path.join(base_dir, 'datasets', 'processed')\n",
    "od_path = os.path.join(processed_dir, '250414_od_matrix_with_hart_designation.csv')\n",
    "\n",
    "od_matrix = pd.read_csv(od_path)\n",
    "# origin and destination nodes should be strings not integers\n",
    "od_matrix['origin_node'] = od_matrix['origin_node'].astype(str)\n",
    "od_matrix['destination_node'] = od_matrix['destination_node'].astype(str)\n",
    "od_matrix['earliest_station_node'] = od_matrix['earliest_station_node'].astype(str)\n",
    "\n",
    "# for_all_road_types = True\n",
    "# weight = 0.05\n",
    "# interval_length='60s'\n",
    "# min_speed = 1\n",
    "\n",
    "# edges_df, in_route_veh_df, completed_veh_df = run_full_loop(od_matrix, \n",
    "#                             weight=weight, \n",
    "#                             min_speed=min_speed, \n",
    "#                             for_all_road_types=for_all_road_types, \n",
    "#                             interval_length=interval_length,\n",
    "#                             end_time='5:30:00'\n",
    "#                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_od_matrix_to_scenario(od_matrix, simulation_scenario):\n",
    "    if od_matrix['earliest_station_position'].notnull().sum() < simulation_scenario:\n",
    "        raise ValueError(\"The number of earliest station positions is less than the simulation scenario.\")\n",
    "    # create a copy of the od_matrix\n",
    "    od_matrix_adjusted = od_matrix.copy()\n",
    "    # sort ascending on earliest_station_position\n",
    "    od_matrix_adjusted = od_matrix_adjusted.sort_values(by='earliest_station_position', ascending=True)\n",
    "    # for the top # (simulation_scenario) rows, replace 'destination_node' with 'earliest_station_node'\n",
    "    od_matrix_adjusted.loc[od_matrix_adjusted.index[:simulation_scenario], 'destination_node'] = od_matrix_adjusted['earliest_station_node']\n",
    "    # if destination_node is NaN, drop the row]\n",
    "    od_matrix_adjusted = od_matrix_adjusted[~od_matrix_adjusted['destination_node'].isnull()]\n",
    "    od_matrix_adjusted = od_matrix_adjusted[od_matrix_adjusted['destination_node'] != 'nan']\n",
    "    # convert to string\n",
    "    od_matrix_adjusted['destination_node'] = od_matrix_adjusted['destination_node'].astype(float).astype(int).astype(str)\n",
    "    # od_matrix_adjusted['origin_node'] = od_matrix_adjusted['origin_node'].astype(str)\n",
    "    return od_matrix_adjusted\n",
    "\n",
    "def run_simulation_scenarios(od_matrix, simulation_scenario_list, save_path):\n",
    "    for_all_road_types = True\n",
    "    weight = 0.05\n",
    "    interval_length='60s'\n",
    "    min_speed = 1\n",
    "    # iterate through the simulation scenarios\n",
    "    for simulation_scenario in simulation_scenario_list:\n",
    "        # make a copy of the od_matrix with the appropriate adjustments\n",
    "        print(f\"simulation: {simulation_scenario}\")\n",
    "        od_matrix_adjusted = adjust_od_matrix_to_scenario(od_matrix, simulation_scenario)\n",
    "        # run the simulation\n",
    "        edges_df, in_route_veh_df, completed_veh_df = run_full_loop(od_matrix_adjusted, \n",
    "                            weight=weight, \n",
    "                            min_speed=min_speed, \n",
    "                            for_all_road_types=for_all_road_types, \n",
    "                            interval_length=interval_length,\n",
    "                            )\n",
    "        # save the results to a csv file\n",
    "        completed_veh_df.to_csv(os.path.join(save_path, f\"completed_veh_df_{simulation_scenario}.csv\"), index=False)\n",
    "        print(f\"Simulation scenario {simulation_scenario} completed and saved\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation_scenario_list = [10_000, 20_000, 30_000, 40_000, 50_000]\n",
    "# save_path = os.path.join(processed_dir, 'simulation_scenarios')\n",
    "\n",
    "# run_simulation_scenarios(od_matrix, simulation_scenario_list, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate the difference in travel time between the scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_status_path = os.path.join(processed_dir, 'congestion_iterations_new_equation', 'interval_60_congestion_weight_0.05_for_all_road_types_1mph.csv')\n",
    "base_status_df = pd.read_csv(base_status_path)\n",
    "\n",
    "test_status_path = os.path.join(processed_dir, 'simulation_scenarios', 'completed_veh_df_10000.csv')\n",
    "test_status_df = pd.read_csv(test_status_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "town_tracts = [\n",
    "    '15003980200',\n",
    "    '15003981400',\n",
    "    '15003981300',\n",
    "    '15003005900',\n",
    "    '15003006000',\n",
    "    '15003005800',\n",
    "    '15003005700',\n",
    "    '15003005200',\n",
    "    '15003004000',\n",
    "    '15003003900',\n",
    "    '15003003801',\n",
    "    '15003003802',\n",
    "    '15003003703',\n",
    "    '15003003702',\n",
    "    '15003003606',\n",
    "    '15003003605',\n",
    "    '15003003603',\n",
    "    '15003003604',\n",
    "    '15003003701',\n",
    "    '15003001906',\n",
    "    '15003001905',\n",
    "    '15003001907',\n",
    "    '15003001901'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check what the 'Town' Tracts look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopandas as gpd\n",
    "# from keplergl import KeplerGl\n",
    "# from shapely import wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets_dir = os.path.join(base_dir, 'datasets')\n",
    "# tract_path = os.path.join(datasets_dir, '2020_Census_Tracts.geojson')\n",
    "# tracts_gdf = gpd.read_file(tract_path)\n",
    "\n",
    "# town_tracts = tracts_gdf[tracts_gdf['geoid20'].isin(town_tracts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_ = KeplerGl(height=800)\n",
    "\n",
    "# map_.add_data(data=town_tracts, name='Town Tracts')\n",
    "# map_.add_data(data=tracts_gdf, name='All Tracts')\n",
    "\n",
    "# save_path = os.path.join(base_dir, 'maps')\n",
    "# # map_.save_to_html(file_name= save_path + '250415_town_tracts.html', read_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_largest_scenario(simulation_status_folder):\n",
    "    simulation_status_files = glob.glob(os.path.join(simulation_status_folder, \"*.csv\"))\n",
    "\n",
    "    # Create a list of scenario numbers\n",
    "    scenario_numbers = []\n",
    "    for simulation_status_file in simulation_status_files:\n",
    "        scenario_name = os.path.basename(simulation_status_file).split(\"_\")[-1].split(\".\")[0]\n",
    "        try:\n",
    "            scenario_number = int(scenario_name)\n",
    "            scenario_numbers.append(scenario_number)\n",
    "        except ValueError:\n",
    "            # Skip files where the scenario name can't be converted to an integer\n",
    "            continue\n",
    "    # Return the maximum scenario number, or 0 if the list is empty\n",
    "    return max(scenario_numbers) if scenario_numbers else 0\n",
    "\n",
    "def identify_persons_from_simulation(od_matrix, simulation_scenario):\n",
    "    if od_matrix['earliest_station_position'].notnull().sum() < simulation_scenario:\n",
    "        raise ValueError(\"The number of earliest station positions is less than the simulation scenario.\")\n",
    "    # create a copy of the od_matrix\n",
    "    od_matrix_adjusted = od_matrix.copy()\n",
    "    # sort ascending on earliest_station_position\n",
    "    od_matrix_adjusted = od_matrix_adjusted.sort_values(by='earliest_station_position', ascending=True)\n",
    "    return od_matrix_adjusted.iloc[:simulation_scenario]['person_id'].tolist()\n",
    "\n",
    "def calculate_tract_time_difference(base_status_df, simulation_status_df, od_matrix, town_tracts, scenario_name, drop_min_vehicles=20):\n",
    "    od_matrix_copy = od_matrix.copy()\n",
    "    # merge the dataframes on person_id\n",
    "    merged_df = pd.merge(base_status_df, simulation_status_df, on='person_id', suffixes=('_base', '_simulation'))\n",
    "\n",
    "    # Drop rows with NaN values in the relevant columns\n",
    "    merged_df = merged_df.dropna(subset=['completion_time_base', 'completion_time_simulation'])\n",
    "\n",
    "    # take the difference of the two columns\n",
    "    merged_df['completion_time_base'] = pd.to_datetime(merged_df['completion_time_base'], format='%H:%M:%S')\n",
    "    merged_df['completion_time_simulation'] = pd.to_datetime(merged_df['completion_time_simulation'], format='%H:%M:%S')\n",
    "    merged_df['time_difference'] = merged_df['completion_time_base'] - merged_df['completion_time_simulation']\n",
    "    merged_df['time_difference_minutes'] = merged_df['time_difference'].dt.total_seconds() / 60\n",
    "\n",
    "    # merge with the od_matrix on person_id\n",
    "    # convert 5 min designation to actual time and pull out the hour\n",
    "    od_matrix_copy = prepare_departure_time_for_od_matrix(od_matrix_copy, column ='5min_designation')\n",
    "    od_matrix_copy['departure_hour'] = od_matrix_copy['departure_time'].str.split(':').str[0].astype(int)\n",
    "    merged_df = pd.merge(merged_df[['person_id', 'time_difference_minutes']], od_matrix_copy[['person_id', 'origin_tract', 'destination_tract', 'departure_hour']], on='person_id', how='left')\n",
    "    \n",
    "    # filter out origin tract in town_tracts\n",
    "    merged_df['origin_tract'] = merged_df['origin_tract'].astype(str)\n",
    "    merged_df['destination_tract'] = merged_df['destination_tract'].astype(str)\n",
    "    merged_df = merged_df[~merged_df['origin_tract'].isin(town_tracts)].copy()\n",
    "    print(scenario_name)\n",
    "    print(f\"merge_df shape: {merged_df.shape[0]}\")\n",
    "    # filter for destination tract in town_tracts\n",
    "    merged_df = merged_df[merged_df['destination_tract'].isin(town_tracts)].copy()\n",
    "    print(f\"merge_df shape: {merged_df.shape[0]}\")\n",
    "    # filter out person id's that have been manipulated to an earlier destination node\n",
    "    person_id_filter_list = identify_persons_from_simulation(od_matrix, int(scenario_name))\n",
    "    merged_df = merged_df[~merged_df['person_id'].isin(person_id_filter_list)].copy()\n",
    "    print(f\"merge_df shape: {merged_df.shape[0]}\")\n",
    "\n",
    "    # aggregate the data\n",
    "    agg_df = merged_df.groupby(['origin_tract', 'departure_hour']).agg(\n",
    "        time_difference_minutes_mean=('time_difference_minutes', 'mean'),\n",
    "        time_difference_minutes_median=('time_difference_minutes', 'median'),\n",
    "        total_vehicles=('person_id', 'count')\n",
    "    ).reset_index()\n",
    "    # drop tracts that don't meet vehicle threshold\n",
    "    agg_df = agg_df[agg_df['total_vehicles'] >= drop_min_vehicles].copy()\n",
    "    return agg_df\n",
    "\n",
    "def calculate_tract_time_difference_all_scenarios(base_status_df_path, simulation_status_folder, od_matrix, town_tracts):\n",
    "    # max_scenario = identify_largest_scenario(simulation_status_folder)\n",
    "    # (1) read the base status df\n",
    "    base_status_df = pd.read_csv(base_status_df_path)\n",
    "    # (2) get all the simulation status files\n",
    "    simulation_status_files = glob.glob(os.path.join(simulation_status_folder, \"*.csv\"))\n",
    "    # (3) iterate through the files\n",
    "    all_scenarios_df = []\n",
    "    for simulation_status_file in simulation_status_files:\n",
    "        # read the file\n",
    "        simulation_status_df = pd.read_csv(simulation_status_file)\n",
    "        # get the scenario name from the file name\n",
    "        scenario_name = os.path.basename(simulation_status_file).split(\"_\")[-1].split(\".\")[0]\n",
    "        # calculate the time difference\n",
    "        time_difference_df = calculate_tract_time_difference(base_status_df, simulation_status_df, od_matrix, town_tracts, scenario_name)\n",
    "        # add the scenario name to the dataframe\n",
    "        time_difference_df['scenario'] = scenario_name\n",
    "        all_scenarios_df.append(time_difference_df)\n",
    "    # (4) concatenate the dataframes\n",
    "    all_scenarios_df = pd.concat(all_scenarios_df, ignore_index=True)\n",
    "    return all_scenarios_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = calculate_tract_time_difference(base_status_df, test_status_df, od_matrix, town_tracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "merge_df shape: 175146\n",
      "merge_df shape: 67937\n",
      "merge_df shape: 63608\n",
      "30000\n",
      "merge_df shape: 175146\n",
      "merge_df shape: 67937\n",
      "merge_df shape: 47667\n",
      "20000\n",
      "merge_df shape: 175146\n",
      "merge_df shape: 67937\n",
      "merge_df shape: 55591\n",
      "40000\n",
      "merge_df shape: 175146\n",
      "merge_df shape: 67937\n",
      "merge_df shape: 39724\n",
      "50000\n",
      "merge_df shape: 175146\n",
      "merge_df shape: 67937\n",
      "merge_df shape: 30807\n"
     ]
    }
   ],
   "source": [
    "base_status_path = os.path.join(processed_dir, 'congestion_iterations_new_equation', 'interval_60_congestion_weight_0.05_for_all_road_types_1mph.csv')\n",
    "simulation_status_folder = os.path.join(processed_dir, 'simulation_scenarios')\n",
    "save_path = processed_dir\n",
    "\n",
    "test = calculate_tract_time_difference_all_scenarios(base_status_path, simulation_status_folder, od_matrix, town_tracts)\n",
    "\n",
    "# test.to_csv(os.path.join(save_path, \"250415_simulation_scenarios_time_difference.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_difference_minutes_sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>1578.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>2642.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30000</th>\n",
       "      <td>3373.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40000</th>\n",
       "      <td>3864.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50000</th>\n",
       "      <td>4241.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          time_difference_minutes_sum\n",
       "scenario                             \n",
       "10000                          1578.0\n",
       "20000                          2642.5\n",
       "30000                          3373.5\n",
       "40000                          3864.5\n",
       "50000                          4241.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby(['scenario']).agg(\n",
    "    time_difference_minutes_sum=('time_difference_minutes_median', 'sum'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate total time saved for each scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tract_time_difference_raw(base_status_df, simulation_status_df, scenario_name):\n",
    "    # merge the dataframes on person_id\n",
    "    merged_df = pd.merge(base_status_df, simulation_status_df, on='person_id', suffixes=('_base', '_simulation'))\n",
    "\n",
    "    # Drop rows with NaN values in the relevant columns\n",
    "    merged_df = merged_df.dropna(subset=['completion_time_base', 'completion_time_simulation'])\n",
    "\n",
    "    # take the difference of the two columns\n",
    "    merged_df['completion_time_base'] = pd.to_datetime(merged_df['completion_time_base'], format='%H:%M:%S')\n",
    "    merged_df['completion_time_simulation'] = pd.to_datetime(merged_df['completion_time_simulation'], format='%H:%M:%S')\n",
    "    merged_df['time_difference'] = merged_df['completion_time_base'] - merged_df['completion_time_simulation']\n",
    "    merged_df['time_difference_minutes'] = merged_df['time_difference'].dt.total_seconds() / 60\n",
    "\n",
    "    # filter out the persons who have been moved to an earlier destination node\n",
    "    print(scenario_name)\n",
    "    person_id_filter_list = identify_persons_from_simulation(od_matrix, int(scenario_name))\n",
    "    print(f\"merged before filter: {merged_df.shape[0]}\")\n",
    "    merged_df = merged_df[~merged_df['person_id'].isin(person_id_filter_list)].copy()\n",
    "    print(f\"merged after filter: {merged_df.shape[0]}\")\n",
    "    return merged_df\n",
    "\n",
    "def calculate_time_difference_max_scenarios_raw(base_status_df_path, simulation_status_folder):\n",
    "    max_scenario = identify_largest_scenario(simulation_status_folder)\n",
    "    # (1) read the base status df\n",
    "    base_status_df = pd.read_csv(base_status_df_path)\n",
    "    # (2) get all the simulation status files\n",
    "    simulation_status_files = glob.glob(os.path.join(simulation_status_folder, \"*.csv\"))\n",
    "    # (3) iterate through the files\n",
    "    all_scenarios_df = []\n",
    "    for simulation_status_file in simulation_status_files:\n",
    "        # read the file\n",
    "        simulation_status_df = pd.read_csv(simulation_status_file)\n",
    "        # get the scenario name from the file name\n",
    "        scenario_name = os.path.basename(simulation_status_file).split(\"_\")[-1].split(\".\")[0]\n",
    "        # calculate the time difference\n",
    "        time_difference_df = calculate_tract_time_difference_raw(base_status_df, simulation_status_df, max_scenario)\n",
    "        # add the scenario name to the dataframe\n",
    "        time_difference_df['scenario'] = scenario_name\n",
    "        all_scenarios_df.append(time_difference_df)\n",
    "    # (4) concatenate the dataframes\n",
    "    all_scenarios_df = pd.concat(all_scenarios_df, ignore_index=True)\n",
    "    # (5) aggregate on scenario and sum\n",
    "    all_scenarios_df = all_scenarios_df.groupby(['scenario']).agg(\n",
    "        time_difference_minutes_sum=('time_difference_minutes', 'sum'),\n",
    "    ).reset_index()\n",
    "    all_scenarios_df['hours_saved'] = all_scenarios_df['time_difference_minutes_sum'] / 60\n",
    "    return all_scenarios_df\n",
    "\n",
    "def calculate_time_difference_all_scenarios_raw(base_status_df_path, simulation_status_folder):\n",
    "    # max_scenario = identify_largest_scenario(simulation_status_folder)\n",
    "    # (1) read the base status df\n",
    "    base_status_df = pd.read_csv(base_status_df_path)\n",
    "    # (2) get all the simulation status files\n",
    "    simulation_status_files = glob.glob(os.path.join(simulation_status_folder, \"*.csv\"))\n",
    "    # (3) iterate through the files\n",
    "    all_scenarios_df = []\n",
    "    for simulation_status_file in simulation_status_files:\n",
    "        # read the file\n",
    "        simulation_status_df = pd.read_csv(simulation_status_file)\n",
    "        # get the scenario name from the file name\n",
    "        scenario_name = os.path.basename(simulation_status_file).split(\"_\")[-1].split(\".\")[0]\n",
    "        # calculate the time difference\n",
    "        time_difference_df = calculate_tract_time_difference_raw(base_status_df, simulation_status_df, scenario_name)\n",
    "        # add the scenario name to the dataframe\n",
    "        time_difference_df['scenario'] = scenario_name\n",
    "        all_scenarios_df.append(time_difference_df)\n",
    "    # (4) concatenate the dataframes\n",
    "    all_scenarios_df = pd.concat(all_scenarios_df, ignore_index=True)\n",
    "    # (5) aggregate on scenario and sum\n",
    "    all_scenarios_df = all_scenarios_df.groupby(['scenario']).agg(\n",
    "        time_difference_minutes_sum=('time_difference_minutes', 'sum'),\n",
    "    ).reset_index()\n",
    "    all_scenarios_df['hours_saved'] = all_scenarios_df['time_difference_minutes_sum'] / 60\n",
    "    return all_scenarios_df\n",
    "\n",
    "def create_scenario_summary_table(base_status_df_path, simulation_status_folder):\n",
    "    max_scenario = calculate_time_difference_max_scenarios_raw(base_status_df_path, simulation_status_folder)\n",
    "    all_scenario = calculate_time_difference_all_scenarios_raw(base_status_df_path, simulation_status_folder)\n",
    "    # merge the two dataframes on scenario\n",
    "    all_scenario = pd.merge(all_scenario, max_scenario, on='scenario', suffixes=('_all', '_max'))\n",
    "    all_scenario = all_scenario[['scenario', 'hours_saved_all', 'hours_saved_max']]\n",
    "    # rename \n",
    "    all_scenario.columns = ['scenario', 'hours_saved_dropping_scenario_vehicle_count', 'hours_saved_dropping_50k_vehicles']\n",
    "    # round to nearest int\n",
    "    all_scenario['hours_saved_dropping_scenario_vehicle_count'] = all_scenario['hours_saved_dropping_scenario_vehicle_count'].round(0).astype(int)\n",
    "    all_scenario['hours_saved_dropping_50k_vehicles'] = all_scenario['hours_saved_dropping_50k_vehicles'].round(0).astype(int)\n",
    "    return all_scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "merged before filter: 191218\n",
      "merged after filter: 141219\n",
      "50000\n",
      "merged before filter: 191218\n",
      "merged after filter: 141219\n",
      "50000\n",
      "merged before filter: 191218\n",
      "merged after filter: 141219\n",
      "50000\n",
      "merged before filter: 191218\n",
      "merged after filter: 141219\n",
      "50000\n",
      "merged before filter: 191218\n",
      "merged after filter: 141219\n",
      "10000\n",
      "merged before filter: 191218\n",
      "merged after filter: 181219\n",
      "30000\n",
      "merged before filter: 191218\n",
      "merged after filter: 161219\n",
      "20000\n",
      "merged before filter: 191218\n",
      "merged after filter: 171219\n",
      "40000\n",
      "merged before filter: 191218\n",
      "merged after filter: 151219\n",
      "50000\n",
      "merged before filter: 191218\n",
      "merged after filter: 141219\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>hours_saved_dropping_scenario_vehicle_count</th>\n",
       "      <th>hours_saved_dropping_50k_vehicles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>2674</td>\n",
       "      <td>1888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>2869</td>\n",
       "      <td>2159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30000</td>\n",
       "      <td>3996</td>\n",
       "      <td>3402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40000</td>\n",
       "      <td>3703</td>\n",
       "      <td>3414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>3659</td>\n",
       "      <td>3659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  scenario  hours_saved_dropping_scenario_vehicle_count  \\\n",
       "0    10000                                         2674   \n",
       "1    20000                                         2869   \n",
       "2    30000                                         3996   \n",
       "3    40000                                         3703   \n",
       "4    50000                                         3659   \n",
       "\n",
       "   hours_saved_dropping_50k_vehicles  \n",
       "0                               1888  \n",
       "1                               2159  \n",
       "2                               3402  \n",
       "3                               3414  \n",
       "4                               3659  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_scenario_summary_table(base_status_path, simulation_status_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "250110_traffic_simulation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
